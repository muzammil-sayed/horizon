{
    "version": 1,
    "serial": 9,
    "modules": [
        {
            "path": [
                "root"
            ],
            "outputs": {},
            "resources": {
                "aws_autoscaling_group.mysql_master_asg_az1": {
                    "type": "aws_autoscaling_group",
                    "depends_on": [
                        "aws_elb.mysql_master_elb",
                        "aws_launch_configuration.mysql_node"
                    ],
                    "primary": {
                        "id": "test-cact-mysql-master-az1-asg",
                        "attributes": {
                            "availability_zones.#": "1",
                            "availability_zones.2487133097": "us-west-2a",
                            "default_cooldown": "300",
                            "desired_capacity": "1",
                            "force_delete": "false",
                            "health_check_grace_period": "300",
                            "health_check_type": "EC2",
                            "id": "test-cact-mysql-master-az1-asg",
                            "launch_configuration": "cact-mysql-server-mqdwi4zwefbhlbjzj5w2siayz4",
                            "load_balancers.#": "1",
                            "load_balancers.3194687528": "cloudalytics-container-test-mm",
                            "max_size": "1",
                            "metrics_granularity": "1Minute",
                            "min_size": "1",
                            "name": "test-cact-mysql-master-az1-asg",
                            "placement_group": "",
                            "tag.#": "7",
                            "tag.1116357458.key": "Jive_service",
                            "tag.1116357458.propagate_at_launch": "true",
                            "tag.1116357458.value": "cloudalytics-container-test",
                            "tag.1147540291.key": "Account_name",
                            "tag.1147540291.propagate_at_launch": "true",
                            "tag.1147540291.value": "jive-data-pipeline",
                            "tag.1850664732.key": "Pipeline_phase",
                            "tag.1850664732.propagate_at_launch": "true",
                            "tag.1850664732.value": "test",
                            "tag.2119906167.key": "Name",
                            "tag.2119906167.propagate_at_launch": "true",
                            "tag.2119906167.value": "test-cact-mysql-master",
                            "tag.2883601676.key": "Service_component",
                            "tag.2883601676.propagate_at_launch": "true",
                            "tag.2883601676.value": "mysql_master",
                            "tag.3767096825.key": "SLA",
                            "tag.3767096825.propagate_at_launch": "true",
                            "tag.3767096825.value": "non-prod",
                            "tag.4279558224.key": "Region",
                            "tag.4279558224.propagate_at_launch": "true",
                            "tag.4279558224.value": "us-west-2",
                            "termination_policies.#": "0",
                            "vpc_zone_identifier.#": "1",
                            "vpc_zone_identifier.1736361213": "subnet-5def242b",
                            "wait_for_capacity_timeout": "10m"
                        }
                    }
                },
                "aws_elb.mysql_master_elb": {
                    "type": "aws_elb",
                    "depends_on": [
                        "aws_security_group.mysql_ports"
                    ],
                    "primary": {
                        "id": "cloudalytics-container-test-mm",
                        "attributes": {
                            "access_logs.#": "0",
                            "availability_zones.#": "3",
                            "availability_zones.2050015877": "us-west-2c",
                            "availability_zones.221770259": "us-west-2b",
                            "availability_zones.2487133097": "us-west-2a",
                            "connection_draining": "false",
                            "connection_draining_timeout": "300",
                            "cross_zone_load_balancing": "true",
                            "dns_name": "internal-cloudalytics-container-test-mm-1380868787.us-west-2.elb.amazonaws.com",
                            "health_check.#": "1",
                            "health_check.0.healthy_threshold": "2",
                            "health_check.0.interval": "10",
                            "health_check.0.target": "TCP:3306",
                            "health_check.0.timeout": "5",
                            "health_check.0.unhealthy_threshold": "2",
                            "id": "cloudalytics-container-test-mm",
                            "idle_timeout": "60",
                            "instances.#": "1",
                            "instances.535828424": "i-09821a5b526f36a39",
                            "internal": "true",
                            "listener.#": "1",
                            "listener.1711430035.instance_port": "3306",
                            "listener.1711430035.instance_protocol": "tcp",
                            "listener.1711430035.lb_port": "3306",
                            "listener.1711430035.lb_protocol": "tcp",
                            "listener.1711430035.ssl_certificate_id": "",
                            "name": "cloudalytics-container-test-mm",
                            "security_groups.#": "2",
                            "security_groups.692907697": "sg-8268befb",
                            "security_groups.929541476": "sg-1ecac279",
                            "source_security_group": "999547976641/test-instance",
                            "source_security_group_id": "sg-1ecac279",
                            "subnets.#": "3",
                            "subnets.1328737188": "subnet-cb42f4af",
                            "subnets.1696862121": "subnet-47e4ff1e",
                            "subnets.1736361213": "subnet-5def242b",
                            "tags.#": "7",
                            "tags.Account_name": "jive-data-pipeline",
                            "tags.Jive_service": "cloudalytics-container-test",
                            "tags.Name": "test-cact-mysql-master",
                            "tags.Pipeline_phase": "test",
                            "tags.Region": "us-west-2",
                            "tags.SLA": "non-prod",
                            "tags.Service_component": "mysql_master",
                            "zone_id": "Z1H1FL5HABSF5"
                        }
                    }
                },
                "aws_launch_configuration.mysql_node": {
                    "type": "aws_launch_configuration",
                    "depends_on": [
                        "aws_security_group.mysql_ports",
                        "template_file.userdata"
                    ],
                    "primary": {
                        "id": "cact-mysql-server-mqdwi4zwefbhlbjzj5w2siayz4",
                        "attributes": {
                            "associate_public_ip_address": "false",
                            "ebs_block_device.#": "1",
                            "ebs_block_device.3817660160.delete_on_termination": "false",
                            "ebs_block_device.3817660160.device_name": "/dev/xvdm",
                            "ebs_block_device.3817660160.encrypted": "true",
                            "ebs_block_device.3817660160.iops": "0",
                            "ebs_block_device.3817660160.snapshot_id": "",
                            "ebs_block_device.3817660160.volume_size": "20",
                            "ebs_block_device.3817660160.volume_type": "gp2",
                            "ebs_optimized": "false",
                            "enable_monitoring": "true",
                            "ephemeral_block_device.#": "0",
                            "iam_instance_profile": "ebs-attach-and-secrets-profile",
                            "id": "cact-mysql-server-mqdwi4zwefbhlbjzj5w2siayz4",
                            "image_id": "ami-d2c924b2",
                            "instance_type": "t2.small",
                            "key_name": "data-pipeline",
                            "name": "cact-mysql-server-mqdwi4zwefbhlbjzj5w2siayz4",
                            "name_prefix": "cact-mysql-server-",
                            "root_block_device.#": "0",
                            "security_groups.#": "2",
                            "security_groups.692907697": "sg-8268befb",
                            "security_groups.929541476": "sg-1ecac279",
                            "spot_price": "",
                            "user_data": "b620baa94d0da0642852839b2acc71cea8188371"
                        }
                    }
                },
                "aws_route53_record.mysql_route53_alias": {
                    "type": "aws_route53_record",
                    "depends_on": [
                        "aws_elb.mysql_master_elb",
                        "aws_elb.mysql_master_elb"
                    ],
                    "primary": {
                        "id": "Z18Q9DET05Y2Z8_test-cact-mysql-master_A",
                        "attributes": {
                            "alias.#": "1",
                            "alias.514205076.evaluate_target_health": "true",
                            "alias.514205076.name": "internal-cloudalytics-container-test-mm-1380868787.us-west-2.elb.amazonaws.com",
                            "alias.514205076.zone_id": "Z1H1FL5HABSF5",
                            "failover": "",
                            "fqdn": "test-cact-mysql-master.data.jivehosted.com",
                            "health_check_id": "",
                            "id": "Z18Q9DET05Y2Z8_test-cact-mysql-master_A",
                            "name": "test-cact-mysql-master",
                            "records.#": "0",
                            "set_identifier": "",
                            "ttl": "0",
                            "type": "A",
                            "weight": "-1",
                            "zone_id": "Z18Q9DET05Y2Z8"
                        }
                    }
                },
                "aws_security_group.mysql_ports": {
                    "type": "aws_security_group",
                    "primary": {
                        "id": "sg-8268befb",
                        "attributes": {
                            "description": "Allow traffic on ye olde MySQL port(s)",
                            "egress.#": "1",
                            "egress.956249133.cidr_blocks.#": "1",
                            "egress.956249133.cidr_blocks.0": "10.0.0.0/8",
                            "egress.956249133.from_port": "0",
                            "egress.956249133.protocol": "-1",
                            "egress.956249133.security_groups.#": "0",
                            "egress.956249133.self": "false",
                            "egress.956249133.to_port": "0",
                            "id": "sg-8268befb",
                            "ingress.#": "1",
                            "ingress.1098541575.cidr_blocks.#": "1",
                            "ingress.1098541575.cidr_blocks.0": "10.0.0.0/8",
                            "ingress.1098541575.from_port": "3306",
                            "ingress.1098541575.protocol": "tcp",
                            "ingress.1098541575.security_groups.#": "0",
                            "ingress.1098541575.self": "false",
                            "ingress.1098541575.to_port": "3306",
                            "name": "cloudalytics-container-test_mysql_ports",
                            "owner_id": "999547976641",
                            "tags.#": "0",
                            "vpc_id": "vpc-a69238c2"
                        }
                    }
                },
                "aws_security_group_rule.mysql_egress": {
                    "type": "aws_security_group_rule",
                    "depends_on": [
                        "aws_security_group.mysql_ports"
                    ],
                    "primary": {
                        "id": "sgrule-3530256345",
                        "attributes": {
                            "cidr_blocks.#": "1",
                            "cidr_blocks.0": "10.0.0.0/8",
                            "from_port": "0",
                            "id": "sgrule-3530256345",
                            "protocol": "-1",
                            "security_group_id": "sg-8268befb",
                            "self": "false",
                            "to_port": "0",
                            "type": "egress"
                        },
                        "meta": {
                            "schema_version": "2"
                        }
                    }
                },
                "aws_security_group_rule.mysql_port_3306": {
                    "type": "aws_security_group_rule",
                    "depends_on": [
                        "aws_security_group.mysql_ports"
                    ],
                    "primary": {
                        "id": "sgrule-1034167211",
                        "attributes": {
                            "cidr_blocks.#": "1",
                            "cidr_blocks.0": "10.0.0.0/8",
                            "from_port": "3306",
                            "id": "sgrule-1034167211",
                            "protocol": "tcp",
                            "security_group_id": "sg-8268befb",
                            "self": "false",
                            "to_port": "3306",
                            "type": "ingress"
                        },
                        "meta": {
                            "schema_version": "2"
                        }
                    }
                },
                "template_file.userdata": {
                    "type": "template_file",
                    "primary": {
                        "id": "cd78c39fac74f2fc9de65a62b061237cbb89959dff2b44982211ca963d77aac0",
                        "attributes": {
                            "id": "cd78c39fac74f2fc9de65a62b061237cbb89959dff2b44982211ca963d77aac0",
                            "rendered": "#!/bin/bash\n\n# SKIP_EBS_REATTACH - Set to a non-empty string to skip reattaching of any\n#                     unattached matching EBS volumes.\n#                     The ebs_attach script will still run and new volumes\n#                     will be attached/formatted as necessary\n# ADDITIONAL_BUNDLE_NAME - The name of a nexus bundle to download and unpack.\n#                          Leave blank to skip.\n#                          Must contain a script for setting up/calling ansible\n#                          located at/called:\n#           ./ansible/bin/call_ansible.sh\n#\nSKIP_EBS_REATTACH=\nADDITIONAL_BUNDLE_NAME=ansible-playbook-mysql-aws\nADDITIONAL_BUNDLE_VERSION=LATEST\n\nfunction_prep() {\n    # Get pip for awscli\n    yum install -y epel-release\n    yum install -y python-pip\n    pip install awscli\n}\n\nfunction_ebs_attach() {\n    cat \u003c\u003c'EOF' \u003e /tmp/ebs_mount.sh\n#!/bin/bash -v\n#\n# Usage:\n# ./ebs_mount.sh -d \u003cdevice:mountpoint\u003e[,\u003cdevice:mountpoint\u003e...]\n#\n# Example:\n# ./ebs_mount.sh -d /dev/xvdm:/data/elasticsearch,/dev/xvdn:/data/more_data\n#\ndeclare -r instance_id=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)\ndeclare -r avail_zone=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)\n\nregion=\"us-west-2\"\n\nwhile getopts \"d:n:p:\" opt; do\n  case \"$opt\" in\n  d) devices=$OPTARG\n     ;;\n  esac\ndone\n\nif [ -z $name ]\nthen\n  name=$(aws ec2 describe-instances --instance-ids ${instance_id} --region ${region} --query 'Reservations[0].Instances[0].Tags[?Key==`Name`]' | python -c 'import sys, json; print json.load(sys.stdin)[0][\"Value\"]')\nfi\n\npipeline_phase=$(aws ec2 describe-instances --instance-ids ${instance_id} --region ${region} --query 'Reservations[0].Instances[0].Tags[?Key==`Pipeline_phase`]' | python -c 'import sys, json; print json.load(sys.stdin)[0][\"Value\"]')\njive_service=$(aws ec2 describe-instances --instance-ids ${instance_id} --region ${region} --query 'Reservations[0].Instances[0].Tags[?Key==`Jive_service`]' | python -c 'import sys, json; print json.load(sys.stdin)[0][\"Value\"]')\n\necho \"Pipeline_phase: ${pipeline_phase}\"\necho \"Jive_service: ${jive_service}\"\n\nOLD_IFS=$IFS\nIFS=','\nfor dev_mp_pair in $devices\ndo\n  # I have no idea what I'm doing\n  IFS=':' read -ra PAIR \u003c\u003c\u003c \"$dev_mp_pair\"\n  IFS=','\n  device=${PAIR[0]}\n  mountp=${PAIR[1]}\n  echo \"Device: ${device}\"\n  if [ -z $device ]\n  then\n    echo \"[ERROR] Did you specify a device name?\"\n    continue\n  fi\n\n  echo \"MountP: ${mountp}\"\n  if [ -z $mountp ]\n  then\n    echo \"[ERROR] Did you specify a mount point?\"\n    continue\n  fi\n\n  mkdir -p ${mountp}\n\n  if [ -z ${SKIP_EBS_REATTACH} ]\n  then\n    # Search for existing tagged EBS volume (in current AZ)\n    echo \"aws ec2 describe-volumes --region=${region} --filters Name=availability-zone,Values=${avail_zone} Name=tag:Pipeline_phase,Values=${pipeline_phase} Name=tag:Jive_service,Values=${jive_service} Name=status,Values=available Name=tag:device,Values=${device} Name=tag:Name,Values=${name} | python -c 'import sys, json; print json.load(sys.stdin)[\\\"Volumes\\\"][0][\\\"VolumeId\\\"]'\"\n    previous_volume=$(aws ec2 describe-volumes --region=${region} --filters Name=availability-zone,Values=${avail_zone} Name=status,Values=available Name=tag:device,Values=${device} Name=tag:Name,Values=${name} Name=tag:Pipeline_phase,Values=${pipeline_phase} Name=tag:Jive_service,Values=${jive_service} | python -c 'import sys, json; print json.load(sys.stdin)[\"Volumes\"][0][\"VolumeId\"]')\n    echo \"Previous volume: ${previous_volume}\"\n  else\n    previous_volume=\"\"\n    echo \"SKIP_EBS_REATTACH is set, not attempting to reattach old volume(s)\"\n  fi\n\n  # find current volume id\n  echo \"aws ec2 describe-volumes --region ${region} --filters Name=availability-zone,Values=${avail_zone} Name=status,Values=in-use Name=attachment.instance-id,Values=${instance_id} Name=attachment.device,Values=${device} | python -c 'import sys, json; print json.load(sys.stdin)[\\\"Volumes\\\"][0][\\\"VolumeId\\\"]'\"\n  current_volume=$(aws ec2 describe-volumes --region ${region} --filters Name=availability-zone,Values=${avail_zone} Name=status,Values=in-use Name=attachment.instance-id,Values=${instance_id} Name=attachment.device,Values=${device} | python -c 'import sys, json; print json.load(sys.stdin)[\"Volumes\"][0][\"VolumeId\"]')\n\n  if [ $? -ne 0 ]\n  then\n    echo \"[ERROR] Failed to get current volume ID for ${device}\"\n    continue\n  fi\n\n  echo \"Current volume: ${current_volume}\"\n\n  if [ ! -z $previous_volume ]\n  then\n\n    # detach current EBS\n    echo \"detaching current volume: ${current_volume}\"\n    aws ec2 detach-volume --region ${region} --volume-id ${current_volume}\n    if [ $? -ne 0 ]\n    then\n      echo \"[ERROR] Failed to detach current volume: ${current_volume}\"\n      continue\n    fi\n\n    # sleep X seconds or something? to give AWS time to detach\n    echo \"sleeping for 120 to allow aws time to get its ducks in a row\"\n    sleep 120\n\n    # attach existing EBS\n    aws ec2 attach-volume --region ${region} --volume-id ${previous_volume} --instance-id ${instance_id} --device ${device}\n    if [ $? -ne 0 ]\n    then\n      echo \"[ERROR] Failed to attach previous volume: ${previous_volume}\"\n      continue\n    fi\n\n    # sleep X seconds or something? to give AWS time to attach\n    echo \"sleeping for 120 to allow aws time to get its ducks in a row again\"\n    sleep 120\n\n    current_volume=${previous_volume}\n\n  else\n    # no previous volume found. assume tabula rasa\n    echo \"No previous volume found. Proceeding...\"\n    echo \"mkfs -t ext4 ${device}\"\n    mkfs -t ext4 ${device}\n  fi\n  \n  echo \"mount ${device} ${mountp}\"\n  mount ${device} ${mountp}\n  echo \"${device} ${mountp} ext4 defaults,nofail 0 2\" \u003e\u003e /etc/fstab\n\n  # add tags to the volume?\n  echo \"aws ec2 create-tags --region ${region} --resources ${current_volume} --tags Key=Name,Value=\\\"${name}\\\" Key=device,Value=${device} Key=Pipeline_phase,Value=${pipeline_phase} Key=Jive_service,Value=${jive_service}\"\n  aws ec2 create-tags --region ${region} --resources ${current_volume} --tags Key=Name,Value=\"${name}\" Key=device,Value=${device} Key=Pipeline_phase,Value=${pipeline_phase} Key=Jive_service,Value=${jive_service}\n\ndone\nIFS=$OLD_IFS\nEOF\n    # Run script to download latest Ansible artifact and unpack\n    chmod +x /tmp/ebs_mount.sh\n    /tmp/ebs_mount.sh -d /dev/xvdm:/data 2\u003e\u00261 \u003e\u003e /tmp/ebs_mount.log\n}\n\nfunction_nexus() {\n    # URL redirect fails without this entry\n    echo \"10.10.100.155 nexus-int.eng.jiveland.com\" \u003e\u003e /etc/hosts\n\n    # Script to download Ansible artifact from Nexus\n    cat \u003c\u003c'EOF' \u003e /tmp/get_nexus_artifact.sh\n#!/bin/bash\n# Argument = -h -v -i groupId:artifactId:version -c classifier -p packaging -r repository\n\n# Define Nexus Configuration\nNEXUS_BASE=nexus-int.eng.jiveland.com\nREST_PATH=/service/local\nART_REDIR=/artifact/maven/redirect\n\n# Read in Complete Set of Coordinates from the Command Line\nGROUP_ID=\nARTIFACT_ID=\nVERSION=\"LATEST\"\nCLASSIFIER=\"\"\nPACKAGING=tar.gz\nREPO=\"candidates\"\nVERBOSE=0\n\nwhile getopts \"hvi:c:p:\" OPTION\ndo\n     case $OPTION in\n         h)\n             usage\n             exit 1\n             ;;\n         i)\n\t     OIFS=$IFS\n             IFS=\":\"\n\t     GAV_COORD=( $OPTARG )\n\t     GROUP_ID=${GAV_COORD[0]}\n             ARTIFACT_ID=${GAV_COORD[1]}\n             VERSION=${GAV_COORD[2]}\n\t     IFS=$OIFS\n             ;;\n         c)\n             CLASSIFIER=$OPTARG\n             ;;\n         p)\n             PACKAGING=$OPTARG\n             ;;\n         v)\n             VERBOSE=1\n             ;;\n         ?)\n             usage\n             exit\n             ;;\n     esac\ndone\n\nif [[ -z $GROUP_ID ]] || [[ -z $ARTIFACT_ID ]] || [[ -z $VERSION ]]\nthen\n     echo \"BAD ARGUMENTS: Either groupId, artifactId, or version was not supplied\" \u003e\u00262\n     usage\n     exit 1\nfi\n\n# Construct the base URL\nREDIRECT_URL=${NEXUS_BASE}${REST_PATH}${ART_REDIR}\n\n# Generate the list of parameters\nPARAM_KEYS=( g a v r p c )\nPARAM_VALUES=( $GROUP_ID $ARTIFACT_ID $VERSION $REPO $PACKAGING $CLASSIFIER )\nPARAMS=\"\"\nfor index in ${!PARAM_KEYS[*]}\ndo\n  if [[ ${PARAM_VALUES[$index]} != \"\" ]]\n  then\n    PARAMS=\"${PARAMS}${PARAM_KEYS[$index]}=${PARAM_VALUES[$index]}\u0026\"\n  fi\ndone\n\nREDIRECT_URL=\"${REDIRECT_URL}?${PARAMS}\"\n\necho \"Fetching Artifact from $REDIRECT_URL...\" \u003e\u00262\ncurl -sS -L ${REDIRECT_URL}\nEOF\n    # Run script to download latest Ansible artifact and unpack\n    chmod +x /tmp/get_nexus_artifact.sh\n    /tmp/get_nexus_artifact.sh -i com.jivesoftware.techops:ansible-common:LATEST \u003e /tmp/ansible-common.tar.gz\n    if [ ! -z \"$ADDITIONAL_BUNDLE_NAME\" ]\n    then\n      aws configure set s3.signature_version s3v4\n      aws s3 cp s3://us-west-2-jive-data-pipeline-playbooks/${ADDITIONAL_BUNDLE_NAME}/${ADDITIONAL_BUNDLE_NAME}-${ADDITIONAL_BUNDLE_VERSION}.tgz /tmp/${ADDITIONAL_BUNDLE_NAME}-${ADDITIONAL_BUNDLE_VERSION}.tgz\n    fi\n}\n\nfunction_ansible() {\n    # Need Sudo TTY\n    sed -i s/'Defaults    requiretty'/'#Defaults    requiretty'/ /etc/sudoers\n    # Disable SELINUX for SSSD\n    sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config\n    setenforce 0\n    # Create Ansible working directories\n    mkdir -p /tmp/ansible-common\n    tar xf /tmp/ansible-common.tar.gz -C /tmp/ansible-common/\n    if [ ! -z \"$ADDITIONAL_BUNDLE_NAME\" ]\n    then\n      mkdir -p /tmp/${ADDITIONAL_BUNDLE_NAME}-${ADDITIONAL_BUNDLE_VERSION}\n      tar xf /tmp/${ADDITIONAL_BUNDLE_NAME}-${ADDITIONAL_BUNDLE_VERSION}.tgz -C /tmp/${ADDITIONAL_BUNDLE_NAME}-${ADDITIONAL_BUNDLE_VERSION}\n    fi\n    # Set Python to 2.6 and run Ansible locally\n    alternatives --set python /usr/bin/python2.6\n    yum install -y yum-python26 python-boto ansible\n\n    # Script to run Ansible locally\n    cat \u003c\u003cEOF \u003e /tmp/ansible-common/run_ansible.sh\n#!/bin/bash\n\nansible-playbook -i localhost /tmp/ansible-common/playbook-generic-node.yml --connection=local\nif [ ! -z \"$ADDITIONAL_BUNDLE_NAME\" ]\nthen\n  /tmp/${ADDITIONAL_BUNDLE_NAME}-${ADDITIONAL_BUNDLE_VERSION}/bin/call_ansible.sh\nfi\nEOF\n    # Run Ansible\n    chmod +x /tmp/ansible-common/run_ansible.sh\n    /tmp/ansible-common/run_ansible.sh \u003e\u003e /tmp/ansible-common/ansible_debug.log\n}\n\nfunction_restart() {\n    # Need to restart for SELINUX change.\n    shutdown -r now\n}\n\n# Run the things\nfunction_prep\nfunction_ebs_attach\nfunction_nexus\nfunction_ansible\n#function_restart\n",
                            "template": "#!/bin/bash\n\n# SKIP_EBS_REATTACH - Set to a non-empty string to skip reattaching of any\n#                     unattached matching EBS volumes.\n#                     The ebs_attach script will still run and new volumes\n#                     will be attached/formatted as necessary\n# ADDITIONAL_BUNDLE_NAME - The name of a nexus bundle to download and unpack.\n#                          Leave blank to skip.\n#                          Must contain a script for setting up/calling ansible\n#                          located at/called:\n#           ./ansible/bin/call_ansible.sh\n#\nSKIP_EBS_REATTACH=${skip_ebs_reattach}\nADDITIONAL_BUNDLE_NAME=${bundle_name}\nADDITIONAL_BUNDLE_VERSION=${bundle_version}\n\nfunction_prep() {\n    # Get pip for awscli\n    yum install -y epel-release\n    yum install -y python-pip\n    pip install awscli\n}\n\nfunction_ebs_attach() {\n    cat \u003c\u003c'EOF' \u003e /tmp/ebs_mount.sh\n#!/bin/bash -v\n#\n# Usage:\n# ./ebs_mount.sh -d \u003cdevice:mountpoint\u003e[,\u003cdevice:mountpoint\u003e...]\n#\n# Example:\n# ./ebs_mount.sh -d /dev/xvdm:/data/elasticsearch,/dev/xvdn:/data/more_data\n#\ndeclare -r instance_id=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)\ndeclare -r avail_zone=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)\n\nregion=\"${region}\"\n\nwhile getopts \"d:n:p:\" opt; do\n  case \"$opt\" in\n  d) devices=$OPTARG\n     ;;\n  esac\ndone\n\nif [ -z $name ]\nthen\n  name=$(aws ec2 describe-instances --instance-ids $${instance_id} --region $${region} --query 'Reservations[0].Instances[0].Tags[?Key==`Name`]' | python -c 'import sys, json; print json.load(sys.stdin)[0][\"Value\"]')\nfi\n\npipeline_phase=$(aws ec2 describe-instances --instance-ids $${instance_id} --region $${region} --query 'Reservations[0].Instances[0].Tags[?Key==`Pipeline_phase`]' | python -c 'import sys, json; print json.load(sys.stdin)[0][\"Value\"]')\njive_service=$(aws ec2 describe-instances --instance-ids $${instance_id} --region $${region} --query 'Reservations[0].Instances[0].Tags[?Key==`Jive_service`]' | python -c 'import sys, json; print json.load(sys.stdin)[0][\"Value\"]')\n\necho \"Pipeline_phase: $${pipeline_phase}\"\necho \"Jive_service: $${jive_service}\"\n\nOLD_IFS=$IFS\nIFS=','\nfor dev_mp_pair in $devices\ndo\n  # I have no idea what I'm doing\n  IFS=':' read -ra PAIR \u003c\u003c\u003c \"$dev_mp_pair\"\n  IFS=','\n  device=$${PAIR[0]}\n  mountp=$${PAIR[1]}\n  echo \"Device: $${device}\"\n  if [ -z $device ]\n  then\n    echo \"[ERROR] Did you specify a device name?\"\n    continue\n  fi\n\n  echo \"MountP: $${mountp}\"\n  if [ -z $mountp ]\n  then\n    echo \"[ERROR] Did you specify a mount point?\"\n    continue\n  fi\n\n  mkdir -p $${mountp}\n\n  if [ -z $${SKIP_EBS_REATTACH} ]\n  then\n    # Search for existing tagged EBS volume (in current AZ)\n    echo \"aws ec2 describe-volumes --region=$${region} --filters Name=availability-zone,Values=$${avail_zone} Name=tag:Pipeline_phase,Values=$${pipeline_phase} Name=tag:Jive_service,Values=$${jive_service} Name=status,Values=available Name=tag:device,Values=$${device} Name=tag:Name,Values=$${name} | python -c 'import sys, json; print json.load(sys.stdin)[\\\"Volumes\\\"][0][\\\"VolumeId\\\"]'\"\n    previous_volume=$(aws ec2 describe-volumes --region=$${region} --filters Name=availability-zone,Values=$${avail_zone} Name=status,Values=available Name=tag:device,Values=$${device} Name=tag:Name,Values=$${name} Name=tag:Pipeline_phase,Values=$${pipeline_phase} Name=tag:Jive_service,Values=$${jive_service} | python -c 'import sys, json; print json.load(sys.stdin)[\"Volumes\"][0][\"VolumeId\"]')\n    echo \"Previous volume: $${previous_volume}\"\n  else\n    previous_volume=\"\"\n    echo \"SKIP_EBS_REATTACH is set, not attempting to reattach old volume(s)\"\n  fi\n\n  # find current volume id\n  echo \"aws ec2 describe-volumes --region $${region} --filters Name=availability-zone,Values=$${avail_zone} Name=status,Values=in-use Name=attachment.instance-id,Values=$${instance_id} Name=attachment.device,Values=$${device} | python -c 'import sys, json; print json.load(sys.stdin)[\\\"Volumes\\\"][0][\\\"VolumeId\\\"]'\"\n  current_volume=$(aws ec2 describe-volumes --region $${region} --filters Name=availability-zone,Values=$${avail_zone} Name=status,Values=in-use Name=attachment.instance-id,Values=$${instance_id} Name=attachment.device,Values=$${device} | python -c 'import sys, json; print json.load(sys.stdin)[\"Volumes\"][0][\"VolumeId\"]')\n\n  if [ $? -ne 0 ]\n  then\n    echo \"[ERROR] Failed to get current volume ID for $${device}\"\n    continue\n  fi\n\n  echo \"Current volume: $${current_volume}\"\n\n  if [ ! -z $previous_volume ]\n  then\n\n    # detach current EBS\n    echo \"detaching current volume: $${current_volume}\"\n    aws ec2 detach-volume --region $${region} --volume-id $${current_volume}\n    if [ $? -ne 0 ]\n    then\n      echo \"[ERROR] Failed to detach current volume: $${current_volume}\"\n      continue\n    fi\n\n    # sleep X seconds or something? to give AWS time to detach\n    echo \"sleeping for 120 to allow aws time to get its ducks in a row\"\n    sleep 120\n\n    # attach existing EBS\n    aws ec2 attach-volume --region $${region} --volume-id $${previous_volume} --instance-id $${instance_id} --device $${device}\n    if [ $? -ne 0 ]\n    then\n      echo \"[ERROR] Failed to attach previous volume: $${previous_volume}\"\n      continue\n    fi\n\n    # sleep X seconds or something? to give AWS time to attach\n    echo \"sleeping for 120 to allow aws time to get its ducks in a row again\"\n    sleep 120\n\n    current_volume=$${previous_volume}\n\n  else\n    # no previous volume found. assume tabula rasa\n    echo \"No previous volume found. Proceeding...\"\n    echo \"mkfs -t ext4 $${device}\"\n    mkfs -t ext4 $${device}\n  fi\n  \n  echo \"mount $${device} $${mountp}\"\n  mount $${device} $${mountp}\n  echo \"$${device} $${mountp} ext4 defaults,nofail 0 2\" \u003e\u003e /etc/fstab\n\n  # add tags to the volume?\n  echo \"aws ec2 create-tags --region $${region} --resources $${current_volume} --tags Key=Name,Value=\\\"$${name}\\\" Key=device,Value=$${device} Key=Pipeline_phase,Value=$${pipeline_phase} Key=Jive_service,Value=$${jive_service}\"\n  aws ec2 create-tags --region $${region} --resources $${current_volume} --tags Key=Name,Value=\"$${name}\" Key=device,Value=$${device} Key=Pipeline_phase,Value=$${pipeline_phase} Key=Jive_service,Value=$${jive_service}\n\ndone\nIFS=$OLD_IFS\nEOF\n    # Run script to download latest Ansible artifact and unpack\n    chmod +x /tmp/ebs_mount.sh\n    /tmp/ebs_mount.sh -d ${devices} 2\u003e\u00261 \u003e\u003e /tmp/ebs_mount.log\n}\n\nfunction_nexus() {\n    # URL redirect fails without this entry\n    echo \"10.10.100.155 nexus-int.eng.jiveland.com\" \u003e\u003e /etc/hosts\n\n    # Script to download Ansible artifact from Nexus\n    cat \u003c\u003c'EOF' \u003e /tmp/get_nexus_artifact.sh\n#!/bin/bash\n# Argument = -h -v -i groupId:artifactId:version -c classifier -p packaging -r repository\n\n# Define Nexus Configuration\nNEXUS_BASE=nexus-int.eng.jiveland.com\nREST_PATH=/service/local\nART_REDIR=/artifact/maven/redirect\n\n# Read in Complete Set of Coordinates from the Command Line\nGROUP_ID=\nARTIFACT_ID=\nVERSION=\"LATEST\"\nCLASSIFIER=\"\"\nPACKAGING=tar.gz\nREPO=\"candidates\"\nVERBOSE=0\n\nwhile getopts \"hvi:c:p:\" OPTION\ndo\n     case $OPTION in\n         h)\n             usage\n             exit 1\n             ;;\n         i)\n\t     OIFS=$IFS\n             IFS=\":\"\n\t     GAV_COORD=( $OPTARG )\n\t     GROUP_ID=$${GAV_COORD[0]}\n             ARTIFACT_ID=$${GAV_COORD[1]}\n             VERSION=$${GAV_COORD[2]}\n\t     IFS=$OIFS\n             ;;\n         c)\n             CLASSIFIER=$OPTARG\n             ;;\n         p)\n             PACKAGING=$OPTARG\n             ;;\n         v)\n             VERBOSE=1\n             ;;\n         ?)\n             usage\n             exit\n             ;;\n     esac\ndone\n\nif [[ -z $GROUP_ID ]] || [[ -z $ARTIFACT_ID ]] || [[ -z $VERSION ]]\nthen\n     echo \"BAD ARGUMENTS: Either groupId, artifactId, or version was not supplied\" \u003e\u00262\n     usage\n     exit 1\nfi\n\n# Construct the base URL\nREDIRECT_URL=$${NEXUS_BASE}$${REST_PATH}$${ART_REDIR}\n\n# Generate the list of parameters\nPARAM_KEYS=( g a v r p c )\nPARAM_VALUES=( $GROUP_ID $ARTIFACT_ID $VERSION $REPO $PACKAGING $CLASSIFIER )\nPARAMS=\"\"\nfor index in $${!PARAM_KEYS[*]}\ndo\n  if [[ $${PARAM_VALUES[$index]} != \"\" ]]\n  then\n    PARAMS=\"$${PARAMS}$${PARAM_KEYS[$index]}=$${PARAM_VALUES[$index]}\u0026\"\n  fi\ndone\n\nREDIRECT_URL=\"$${REDIRECT_URL}?$${PARAMS}\"\n\necho \"Fetching Artifact from $REDIRECT_URL...\" \u003e\u00262\ncurl -sS -L $${REDIRECT_URL}\nEOF\n    # Run script to download latest Ansible artifact and unpack\n    chmod +x /tmp/get_nexus_artifact.sh\n    /tmp/get_nexus_artifact.sh -i com.jivesoftware.techops:ansible-common:LATEST \u003e /tmp/ansible-common.tar.gz\n    if [ ! -z \"$ADDITIONAL_BUNDLE_NAME\" ]\n    then\n      aws configure set s3.signature_version s3v4\n      aws s3 cp s3://us-west-2-jive-data-pipeline-playbooks/$${ADDITIONAL_BUNDLE_NAME}/$${ADDITIONAL_BUNDLE_NAME}-$${ADDITIONAL_BUNDLE_VERSION}.tgz /tmp/$${ADDITIONAL_BUNDLE_NAME}-$${ADDITIONAL_BUNDLE_VERSION}.tgz\n    fi\n}\n\nfunction_ansible() {\n    # Need Sudo TTY\n    sed -i s/'Defaults    requiretty'/'#Defaults    requiretty'/ /etc/sudoers\n    # Disable SELINUX for SSSD\n    sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config\n    setenforce 0\n    # Create Ansible working directories\n    mkdir -p /tmp/ansible-common\n    tar xf /tmp/ansible-common.tar.gz -C /tmp/ansible-common/\n    if [ ! -z \"$ADDITIONAL_BUNDLE_NAME\" ]\n    then\n      mkdir -p /tmp/$${ADDITIONAL_BUNDLE_NAME}-$${ADDITIONAL_BUNDLE_VERSION}\n      tar xf /tmp/$${ADDITIONAL_BUNDLE_NAME}-$${ADDITIONAL_BUNDLE_VERSION}.tgz -C /tmp/$${ADDITIONAL_BUNDLE_NAME}-$${ADDITIONAL_BUNDLE_VERSION}\n    fi\n    # Set Python to 2.6 and run Ansible locally\n    alternatives --set python /usr/bin/python2.6\n    yum install -y yum-python26 python-boto ansible\n\n    # Script to run Ansible locally\n    cat \u003c\u003cEOF \u003e /tmp/ansible-common/run_ansible.sh\n#!/bin/bash\n\nansible-playbook -i localhost /tmp/ansible-common/playbook-generic-node.yml --connection=local\nif [ ! -z \"$ADDITIONAL_BUNDLE_NAME\" ]\nthen\n  /tmp/$${ADDITIONAL_BUNDLE_NAME}-$${ADDITIONAL_BUNDLE_VERSION}/bin/call_ansible.sh\nfi\nEOF\n    # Run Ansible\n    chmod +x /tmp/ansible-common/run_ansible.sh\n    /tmp/ansible-common/run_ansible.sh \u003e\u003e /tmp/ansible-common/ansible_debug.log\n}\n\nfunction_restart() {\n    # Need to restart for SELINUX change.\n    shutdown -r now\n}\n\n# Run the things\nfunction_prep\nfunction_ebs_attach\nfunction_nexus\nfunction_ansible\n#function_restart\n",
                            "vars.#": "7",
                            "vars.account_name": "jive-data-pipeline",
                            "vars.bundle_name": "ansible-playbook-mysql-aws",
                            "vars.bundle_version": "LATEST",
                            "vars.devices": "/dev/xvdm:/data",
                            "vars.pipeline_phase": "test",
                            "vars.region": "us-west-2",
                            "vars.skip_ebs_reattach": ""
                        }
                    }
                }
            }
        }
    ]
}
